{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining Data from data.gouv.fr API\n",
    "\n",
    "To get real financial data for French municipalities and EPCIs:\n",
    "\n",
    "1. Go to https://www.data.gouv.fr/fr/dataservices/explore-api-v2-50/\n",
    "2. Click on \"Explore API\" button\n",
    "3. In the interface:\n",
    "   - Select dataset, for example \"ofgl-base-communes-consolidee\" \n",
    "   - Add filters like year, siren, etc.\n",
    "   - Click \"Execute\" to test the query\n",
    "4. Copy the generated request URL, which will look like:\n",
    "   ```\n",
    "   https://data.ofgl.fr/api/explore/v2.1/catalog/datasets/ofgl-base-communes-consolidee/records?where=...\n",
    "   ```\n",
    "5. Use this URL in code to fetch real data\n",
    "\n",
    "The API returns detailed financial metrics through multiple datasets for frech administrative units including:\n",
    "- Basic info (name, population, etc.)\n",
    "- Operating revenues and expenses\n",
    "- Investment data\n",
    "- Debt metrics\n",
    "- Various financial ratios\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicates from the JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of entries: 37376\n",
      "Number of entries after deduplication: 287\n",
      "Removed 37089 duplicate entries\n",
      "Saved deduplicated data to: /Users/marcolorenz/SIA/populations-ofgl-communes-deduplicated.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load the JSON file\n",
    "with open('/Users/marcolorenz/SIA/ofgl-base-communes-new.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Create a dictionary to track unique entries based on siren\n",
    "unique_entries = {}\n",
    "\n",
    "# Keep only the latest entry for each siren\n",
    "for entry in data:\n",
    "    siren = entry['siren']\n",
    "    if siren not in unique_entries:\n",
    "        unique_entries[siren] = entry\n",
    "    else:\n",
    "        # If we find a duplicate, keep the entry with the most recent population data\n",
    "        if entry.get('ptot_n') is not None:\n",
    "            unique_entries[siren] = entry\n",
    "\n",
    "# Convert back to list\n",
    "deduplicated_data = list(unique_entries.values())\n",
    "\n",
    "# Save the deduplicated data\n",
    "output_filename = '/Users/marcolorenz/SIA/populations-ofgl-communes-deduplicated.json'\n",
    "with open(output_filename, 'w') as f:\n",
    "    json.dump(deduplicated_data, f, indent=4)\n",
    "\n",
    "print(f\"Original number of entries: {len(data)}\")\n",
    "print(f\"Number of entries after deduplication: {len(deduplicated_data)}\")\n",
    "print(f\"Removed {len(data) - len(deduplicated_data)} duplicate entries\")\n",
    "print(f\"Saved deduplicated data to: {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add reference_sirens to the JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 287 communes\n",
      "\n",
      "Example entry:\n",
      "{\n",
      "  \"siren\": \"210100533\",\n",
      "  \"com_code\": \"01053\",\n",
      "  \"com_name\": \"Bourg-en-Bresse\",\n",
      "  \"epci_code\": \"200071751\",\n",
      "  \"epci_name\": \"CA du Bassin de Bourg-en-Bresse\",\n",
      "  \"dep_code\": \"01\",\n",
      "  \"dep_name\": \"Ain\",\n",
      "  \"reg_code\": \"84\",\n",
      "  \"reg_name\": \"Auvergne-RhÃ´ne-Alpes\",\n",
      "  \"ptot\": 43363,\n",
      "  \"ptot_n\": 43363,\n",
      "  \"reference_sirens\": [\n",
      "    {\n",
      "      \"siren\": \"216900290\"\n",
      "    },\n",
      "    {\n",
      "      \"siren\": \"216900340\"\n",
      "    },\n",
      "    {\n",
      "      \"siren\": \"212601983\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_and_process_populations(file_path):\n",
    "    # Load the JSON data\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # First deduplicate entries by keeping most recent data for each commune\n",
    "    unique_communes = {}\n",
    "    for entry in data:\n",
    "        siren = entry['siren']\n",
    "        if siren not in unique_communes or entry['ptot'] > unique_communes[siren]['ptot']:\n",
    "            unique_communes[siren] = entry\n",
    "    \n",
    "    # Convert back to list\n",
    "    deduped_data = list(unique_communes.values())\n",
    "    \n",
    "    # Group communes by region code\n",
    "    reg_communes = defaultdict(list)\n",
    "    for entry in deduped_data:\n",
    "        reg_code = entry['reg_code']\n",
    "        reg_communes[reg_code].append(entry)\n",
    "    \n",
    "    # Process each entry to add reference sirens\n",
    "    processed_data = []\n",
    "    for entry in deduped_data:\n",
    "        reg_code = entry['reg_code']\n",
    "        current_ptot = entry['ptot']\n",
    "        current_siren = entry['siren']\n",
    "        \n",
    "        # Get all communes in same region except current one\n",
    "        reg_entries = [\n",
    "            e for e in reg_communes[reg_code] \n",
    "            if e['siren'] != current_siren\n",
    "        ]\n",
    "        \n",
    "        # Sort by population difference\n",
    "        reg_entries.sort(key=lambda x: abs(x['ptot'] - current_ptot))\n",
    "        \n",
    "        # Take the 3 closest ones\n",
    "        reference_sirens = [\n",
    "            {\n",
    "                'siren': e['siren'],\n",
    "            }\n",
    "            for e in reg_entries[:3]\n",
    "        ]\n",
    "        \n",
    "        # Create new entry with reference sirens\n",
    "        processed_entry = {\n",
    "            'siren': entry['siren'],\n",
    "            'com_code': entry['com_code'],\n",
    "            'com_name': entry['com_name'],\n",
    "            'epci_code': entry['epci_code'],\n",
    "            'epci_name': entry['epci_name'],\n",
    "            'dep_code': entry['dep_code'],\n",
    "            'dep_name': entry['dep_name'],\n",
    "            'reg_code': entry['reg_code'],\n",
    "            'reg_name': entry['reg_name'],\n",
    "            'ptot': entry['ptot'],\n",
    "            'ptot_n': entry['ptot_n'],\n",
    "            'reference_sirens': reference_sirens\n",
    "        }\n",
    "        processed_data.append(processed_entry)\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "# Process the file\n",
    "processed_data = load_and_process_populations('/Users/marcolorenz/SIA/ofgl-base-communes-new.json')\n",
    "\n",
    "# Save to new file\n",
    "output_path = 'populations-ofgl-communes-postprocessed.json'\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(processed_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Print example\n",
    "print(f\"\\nProcessed {len(processed_data)} communes\")\n",
    "print(\"\\nExample entry:\")\n",
    "print(json.dumps(processed_data[0], indent=2, ensure_ascii=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
